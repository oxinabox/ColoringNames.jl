{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition nrow(DataFramesMeta.AbstractCompositeDataFrame) in module DataFramesMeta at /home/ubuntu/.julia/v0.5/DataFramesMeta/src/compositedataframe.jl:108 overwritten at /home/ubuntu/.julia/v0.5/DataFramesMeta/src/compositedataframe.jl:109.\n",
      "WARNING: Method definition nrow(DataFramesMeta.AbstractCompositeDataFrame) in module DataFramesMeta at /home/ubuntu/.julia/v0.5/DataFramesMeta/src/compositedataframe.jl:108 overwritten at /home/ubuntu/.julia/v0.5/DataFramesMeta/src/compositedataframe.jl:109.\n"
     ]
    }
   ],
   "source": [
    "using TensorFlow\n",
    "using Distributions\n",
    "using MLDataUtils\n",
    "using SwiftObjectStores\n",
    "using Iterators\n",
    "using ColoringNames\n",
    "using MappedArrays\n",
    "using MLLabelUtils\n",
    "using StaticArrays\n",
    "using Base.Test\n",
    "using ProgressMeter\n",
    "using IJulia\n",
    "using Memoize\n",
    "import DataFramesMeta.@with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Any,1}:\n",
       " (\"Account\",\"AUTH_eca532d8c1e84913bd21d6d22b30f985\")\n",
       " (\"Container\",\"color\")                              \n",
       " (\"Objects\",\"3\")                                    \n",
       " (\"Bytes\",\"84645914\")                               \n",
       " (\"Read ACL\",\"\")                                    \n",
       " (\"Write ACL\",\"\")                                   \n",
       " (\"Sync To\",\"\")                                     \n",
       " (\"Sync Key\",\"\")                                    "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat(serv, \"color\")[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant serv\n",
      "WARNING: redefining constant train_raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108545×2 Array{Any,2}:\n",
       " \"acid green\"  \"(0.328092243187,0.665271966527,0.937254901961)\" \n",
       " \"acid green\"  \"(0.241007194245,0.712820512821,0.764705882353)\" \n",
       " \"acid green\"  \"(0.274706867672,0.780392156863,1.0)\"            \n",
       " \"acid green\"  \"(0.35346215781,0.896103896104,0.905882352941)\"  \n",
       " \"acid green\"  \"(0.22385620915,0.846473029046,0.945098039216)\"  \n",
       " \"acid green\"  \"(0.219101123596,0.700787401575,0.996078431373)\" \n",
       " \"acid green\"  \"(0.205459770115,0.954732510288,0.952941176471)\" \n",
       " \"acid green\"  \"(0.184782608696,0.987124463519,0.913725490196)\" \n",
       " \"acid green\"  \"(0.204225352113,0.883817427386,0.945098039216)\" \n",
       " \"acid green\"  \"(0.253875968992,0.830917874396,0.811764705882)\" \n",
       " \"acid green\"  \"(0.299065420561,0.968325791855,0.866666666667)\" \n",
       " \"acid green\"  \"(0.298711755233,0.93665158371,0.866666666667)\"  \n",
       " \"acid green\"  \"(0.287596899225,0.968468468468,0.870588235294)\" \n",
       " ⋮                                                              \n",
       " \"yuck\"        \"(0.142694063927,0.679069767442,0.843137254902)\" \n",
       " \"yuck\"        \"(0.146505376344,0.751515151515,0.647058823529)\" \n",
       " \"yuck\"        \"(0.133333333333,0.9,0.392156862745)\"            \n",
       " \"yuck\"        \"(0.212598425197,0.55701754386,0.894117647059)\"  \n",
       " \"yuck\"        \"(0.224885844749,0.672811059908,0.850980392157)\" \n",
       " \"yuck\"        \"(0.246124031008,0.597222222222,0.564705882353)\" \n",
       " \"yuck\"        \"(0.193156732892,0.782383419689,0.756862745098)\" \n",
       " \"yuck\"        \"(0.0766283524904,0.462765957447,0.737254901961)\"\n",
       " \"yuck\"        \"(0.0460526315789,0.449704142012,0.662745098039)\"\n",
       " \"yuck\"        \"(0.14347826087,0.688622754491,0.654901960784)\"  \n",
       " \"yuck\"        \"(0.0540540540541,0.308333333333,0.941176470588)\"\n",
       " \"yuck\"        \"(0.125874125874,0.590909090909,0.949019607843)\" "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const serv=SwiftService()\n",
    "const train_raw = get_file(serv, \"color\", \"monroe/train.csv\") do fh\n",
    "    readdlm(fh,'\\t')\n",
    "end\n",
    "\n",
    "const valid_raw = get_file(serv, \"color\", \"monroe/dev.csv\") do fh\n",
    "    readdlm(fh,'\\t')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWARNING: symbol is deprecated, use Symbol instead.\u001b[0m\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in symbol(::String, ::Vararg{String,N"
     ]
    }
   ],
   "source": [
    "const tokenize = morpheme_tokenizer(\"../data/replacement_rules.csv\")\n",
    "@memoize demarcate(tokens, starter=\"<S>\", ender=\"</S>\") = [starter; tokens; ender]\n",
    "\n",
    "@test demarcate([\"a\", \"b\", \"c\"]) == [\"<S>\", \"a\", \"b\", \"c\", \"</S>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "const od =(MLDataUtils.ObsDim.First(), MLDataUtils.ObsDim.Last())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523108-element Array{Array{String,1},1}:\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " String[\"<S>\",\"acid\",\"green\",\"</S>\"]\n",
       " ⋮                                  \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        \n",
       " String[\"<S>\",\"yuck\",\"</S>\"]        "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_data(raw, encoding_=nothing)\n",
    "    const labels = convert(Vector{String}, raw[:,1]);\n",
    "    const hsv_data = convert(Matrix{Float64}, raw[:,2:end]);\n",
    "    const tokenized_labels = demarcate.(tokenize.(labels))\n",
    "    \n",
    "    if encoding_===nothing\n",
    "        const all_tokens = reduce(union, tokenized_labels)\n",
    "        const encoding = labelenc(all_tokens)        \n",
    "    end\n",
    "    const label_inds = map(toks->label2ind.(toks, Scalar(encoding)), tokenized_labels)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mTest Summary: | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×1523108 Array{Int64,2}:\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  …    1    1    1    1    1    1    1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     313  313  313  313  313  313  313\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3       4    4    4    4    4    4    4\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4       0    0    0    0    0    0    0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0       0    0    0    0    0    0    0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  …    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const padded_labels = rpad_to_matrix(label_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mTest Summary: | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m\u001b[1m\u001b[34mTotal\u001b[0m\n",
      "  masks       | \u001b[1m\u001b[32m   3  \u001b[0m\u001b[1m\u001b[34m    3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    }
   ],
   "source": [
    "get_mask(V, dtype=Float32)=cast(cast(V, Bool),dtype)\n",
    "apply_mask(V, mask) = V.*tile(expand_dims(mask, 1), [1, get_shape(V,2)])\n",
    "\n",
    "@testset \"masks\" begin\n",
    "    mask_sess = Session(Graph())\n",
    "    a_val = (\n",
    "    [2.  5  8  9  2\n",
    "     3.  6  4  4  9\n",
    "     4.  7   3  2  4\n",
    "     1.  4  2  4  4]\n",
    "    )\n",
    "    A=constant(a_val)\n",
    "    M = constant([1, 0, 2, 4])\n",
    "    run(mask_sess, initialize_all_variables())\n",
    "    masked = run(mask_sess, apply_mask(A, get_mask(M, Float64)))\n",
    "    @test all(masked[2,:] .== 0)\n",
    "    @test all(masked[1,:] .== a_val[1,:])\n",
    "    @test all(masked[3:4,:] .== a_val[3:4,:])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mTest Summary: | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m\u001b[1m\u001b[34mTotal\u001b[0m\n",
      "  names_from  | \u001b[1m\u001b[32m   3  \u001b[0m\u001b[1m\u001b[34m    3\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition color_to_terms_network(Any, Any) in module Main at In[12]:8 overwritten at In[13]:8.\n",
      "WARNING: Method definition #color_to_terms_network(Array{Any, 1}, Main.#color_to_terms_network, Any, Any) in module Main overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "color_to_terms_network (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEFINITION\n",
    "function color_to_terms_network(n_classes, n_steps;\n",
    "        batch_size = 128,\n",
    "        learning_rate = 0.05,\n",
    "        hidden_layer_size = 256,\n",
    "        embedding_dim = 16\n",
    "    )\n",
    "    n_input = 3 # HSV\n",
    "    \n",
    "        \n",
    "    ###################################\n",
    "    sess = Session(Graph())\n",
    "    tensor_vars = @names_from begin\n",
    "        X_hsv = placeholder(Float32, shape=[batch_size, n_input]; name=\"X_HSVs\")\n",
    "        Term_obs_s = placeholder(Int32, shape=[n_steps+1, batch_size]; name=\"Term_obs_s\")\n",
    "\n",
    "        EmbeddingTable = get_variable(\"TokenEmbeddings\",  [n_classes, embedding_dim], Float32; initializer=Normal(0, .1))\n",
    "\n",
    "        #Mangle Terms into shape\n",
    "        Term_obs_s_out = slice(Term_obs_s, [1,0], [-1,-1]) #Don't want first input \"<S>\" #0based\n",
    "        Term_obs_s_ins = unpack(Term_obs_s+1)[1:end-1]#Don't want last input \"</S>\" (or padding character often but we will handle that seperately)\n",
    "        Term_obs_s_ins_r = reshape.(Term_obs_s_ins, Scalar(batch_size))\n",
    "        Tes = gather.(Scalar(EmbeddingTable), Term_obs_s_ins_r)\n",
    "\n",
    "        TT = reshape(Term_obs_s_out, [n_steps*batch_size]; name=\"Stack_Term_obs_s\")\n",
    "        Term_obs_onehots = one_hot(TT, n_classes)\n",
    "\n",
    "\n",
    "        #Mangle colots into shape\n",
    "        X_h, X_s, X_v = unpack(X_hsv; axis=2)\n",
    "        X_hr = X_h.*2π\n",
    "        X_col = pack((sin(X_hr), cos(X_hr), X_s-0.5, X_v-0.5)) #Smooth hue by breaking into cos and sin, and zero mean everything else\n",
    "        X_col = reshape(X_col, [batch_size, 4]; name = \"X_col\") #Force Shape Inference\n",
    "        Xs = [concat(1, (T, X_col); name=\"Xs$ii\") for (ii,T) in enumerate(Tes)]#Pair color input at each step with previous term #0base\n",
    "\n",
    "        Hs, states = nn.rnn(nn.rnn_cell.LSTMCell(hidden_layer_size), Xs; dtype=Float32)#, sequence_length=n_steps);\n",
    "        W1 = get_variable(\"weights1\", [hidden_layer_size, n_classes], Float32;  initializer=Normal(0, .1))\n",
    "        B1 = get_variable(\"bias1\", [n_classes], Float32;  initializer=Normal(0, .1))\n",
    "        Ls =  [H*W1+B1 for H in Hs]\n",
    "\n",
    "\n",
    "        LL = concat(0, Ls; name=\"Stack_Logits\") #Stack #0base\n",
    "        LL = reshape(LL, [batch_size*n_steps, n_classes]) #Force Shape Inference\n",
    "        LL_masked = apply_mask(LL, get_mask(TT))\n",
    "\n",
    "        Term_preds_onehots = nn.softmax(LL_masked; name=\"Term_preds_onehots\")\n",
    "        Term_preds_onehots_log = nn.log_softmax(LL_masked; name=\"Term_preds_onehots_log\")\n",
    "        Term_preds_s = reshape(indmax(Term_preds_onehots, 2)+1, [n_steps, batch_size]) #TODO: this messes up zero entries, not that it matters\n",
    "\n",
    "        costs  = reduce_sum(Term_obs_onehots.*Term_preds_onehots_log, reduction_indices=[1])\n",
    "        #costs = nn.sparse_softmax_cross_entropy_with_logits(LL, TT+1)\n",
    "        cost = reduce_mean(-costs) #cross entropy\n",
    "\n",
    "        optimizer = train.minimize(train.AdamOptimizer(learning_rate), cost)\n",
    "    end\n",
    "    ########## GET it running\n",
    "    \n",
    "    run(sess, initialize_all_variables())\n",
    "    \n",
    "    return sess, tensor_vars \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Session(Ptr{Void} @0x00007f2d15d18510),Dict{Symbol,Any}(Pair{Symbol,Any}(:X_col,<Tensor X_col_3:1 shape=(128, 4) dtype=Float32>),Pair{Symbol,Any}(:Term_obs_onehots,<Tensor OneHot_3:1 shape=(640, 314) dtype=Float32>),Pair{Symbol,Any}(:Term_obs_s_ins,TensorFlow.Tensor[<Tensor Unpack_6:1 shape=unknown dtype=Int32>,<Tensor Unpack_6:2 shape=unknown dtype=Int32>,<Tensor Unpack_6:3 shape=unknown dtype=Int32>,<Tensor Unpack_6:4 shape=unknown dtype=Int32>,<Tensor Unpack_6:5 shape=unknown dtype=Int32>]),Pair{Symbol,Any}(:Tes,TensorFlow.Tensor[<Tensor Gather_16:1 shape=(128, 16) dtype=Float32>,<Tensor Gather_17:1 shape=(128, 16) dtype=Float32>,<Tensor Gather_18:1 shape=(128, 16) dtype=Float32>,<Tensor Gather_19:1 shape=(128, 16) dtype=Float32>,<Tensor Gather_20:1 shape=(128, 16) dtype=Float32>]),Pair{Symbol,Any}(:Term_preds_onehots,<Tensor Term_preds_onehots_3:1 shape=unknown dtype=Float32>),Pair{Symbol,Any}(:Xs,TensorFlow.Tensor[<Tensor Xs1_3:1 shape=(128, 20) dtype=Float32>,<Tensor Xs2_3:1 shape=(128, 20) dtype=Float32>,<Tensor Xs3_3:1 shape=(128, 20) dtype=Float32>,<Tensor Xs4_3:1 shape=(128, 20) dtype=Float32>,<Tensor Xs5_3:1 shape=(128, 20) dtype=Float32>]),Pair{Symbol,Any}(:W1,TensorFlow.Variable(<Operation 'weights1'>,<Operation 'weights1/Assign'>)),Pair{Symbol,Any}(:X_hsv,<Tensor X_HSVs_4:1 shape=(128, 3) dtype=Float32>),Pair{Symbol,Any}(:Term_obs_s,<Tensor Term_obs_s_4:1 shape=(6, 128) dtype=Int32>),Pair{Symbol,Any}(:optimizer,<Tensor NoOp_6:1 shape=unknown dtype=?>)…))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const batch_size = 128\n",
    "\n",
    "sess, t = color_to_terms_network(nlabel(encoding)+1, size(padded_labels,1)-1;\n",
    "        learning_rate = 0.05,\n",
    "        hidden_layer_size = 256,\n",
    "        embedding_dim = 16,\n",
    "        batch_size=batch_size\n",
    "    )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition train_from_terms!(Any, Base.Associative{Symbol, V<:Any}) in module Main at In[62]:2 overwritten at In[64]:2.\n",
      "\u001b[1m\u001b[34mINFO: The specified values for size and/or count will result in 36 unused data points\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  83%|██████████████████████████████████       |  ETA: 0:02:34"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excessive output truncated after 524439 bytes."
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1531072f0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_from_terms!(sess, t::Associative{Symbol})\n",
    "    batchs = eachbatch(shuffleobs((hsv_data, padded_labels); obsdim=od); size=batch_size, obsdim=od)\n",
    "    local cost_o\n",
    "    @showprogress for (hsv,terms) in batchs\n",
    "        Term_preds_s_o, TT_s_o, cost_o, optimizer_o = run(sess,\n",
    "            [t[:Term_preds_s], t[:TT], t[:cost], t[:optimizer]], \n",
    "        Dict(t[:X_hsv]=>hsv, t[:Term_obs_s]=>terms))\n",
    "    end\n",
    "    @show cost_o\n",
    "end\n",
    "#obs,pred, oo, pp = run(sess, [Term_obs_onehots, Term_preds_onehots, Term_obs_s_out, Term_preds_s], Dict(X_hsv=>hsv_data, Term_obs_s=>padded_labels))\n",
    "train_from_terms!(sess, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x00007f2d15d18510)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        Term_preds_s_o, TT_s_o, cost_o, optimizer_o = run(sess,\n",
    "            [t[:Term_preds_s], t[:TT], t[:cost], t[:optimizer]], \n",
    "        Dict(t[:X_hsv]=>hsv, t[:Term_obs_s]=>terms))\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " TensorFlow.Variable(<Operation 'weights1'>,<Operation 'weights1/Assign'>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorFlow.get_tensors([t[:W1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorFlow.num_outputs( TensorFlow.get_op(t[:W1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: test_it not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: test_it not defined",
      ""
     ]
    }
   ],
   "source": [
    "    if test_it \n",
    "        @assert isa(run(sess, cost, Dict(X_hsv=>hsv_data, Term_obs_s=>padded_labels)), Number )\n",
    "        ## MASK TEST######################\n",
    "        ll, ll2 = run(sess, [ LL_masked, \n",
    "            reshape(tile(expand_dims(get_mask(Term_obs_s_out),2),[1,1,n_classes]).*concat(0, expand_dims.(Ls, Scalar(0))), [batch_size*n_steps, n_classes])\n",
    "        ], Dict(X_hsv=>hsv_data, Term_obs_s=>padded_labels))\n",
    "        @assert ll ≈ ll2\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind2label.(ans, Scalar(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##MASK test code\n",
    "#TODO \n",
    "if test_it \n",
    "        @assert isa(run(sess, cost, Dict(X_hsv=>hsv_data, Term_obs_s=>padded_labels)), Number )\n",
    "        ## MASK TEST######################\n",
    "        ll, ll2 = run(sess, [ LL_masked, \n",
    "            reshape(tile(expand_dims(get_mask(Term_obs_s_out),2),[1,1,8]).*concat(0, expand_dims.(Ls, Scalar(0))), [batch_size*n_steps, n_classes])\n",
    "        ], Dict(X_hsv=>hsv_data, Term_obs_s=>padded_labels))\n",
    "        @assert ll ≈ ll2\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank(X_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function dict2type(vars::Associative{Symbol})\n",
    "     \n",
    "end\n",
    "\"\"\"Take dictionary of named value, and brings each of them into scope with the indicated names\"\"\"\n",
    "macro with_vars(vars, body)\n",
    "    varsdec = Expr(:block, (Expr(:(=), name, :($(esc(vars))[$(name)]) for (name) in vars)...)\n",
    "    quote \n",
    "        $varsdec\n",
    "        $esc(body)\n",
    "    end\n",
    "end\n",
    "\n",
    "@testset \"bring_into_scope\" begin\n",
    "    vartab = Dict(:x2=>2, :y2=>30)\n",
    "    @with_vars vartab begin\n",
    "        @test y2==30\n",
    "        @test x2==2\n",
    "    end\n",
    "    function test_inside_fun()\n",
    "        vartab\n",
    "        @eval :(esc(into_scope(Dict(:x4=>2000, :y4=>300))))\n",
    "        @test y4==300\n",
    "        @test x4==2000\n",
    "    end\n",
    "    test_inside_fun()\n",
    "    @test y4==30\n",
    "    @test x4==2\n",
    "end\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1-pre",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
